{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "torch logistic regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danyamrajuSanjay/Machine_Learning/blob/master/torch_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmgaxaRTNr9L",
        "colab_type": "text"
      },
      "source": [
        "<h1>Logistic Regression</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZjRS_89Nr9M",
        "colab_type": "text"
      },
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<p>In this lab, we will cover logistic regression using PyTorch.</p>\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#Log\">Logistic Function</a></li>\n",
        "    <li><a href=\"#Seq\">Build a Logistic Regression Using nn.Sequential</a></li>\n",
        "    <li><a href=\"#Model\">Build Custom Modules</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>15 min</strong></p>\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiq0cx5Nr9N",
        "colab_type": "text"
      },
      "source": [
        "<h2>Preparation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S54DVDveNr9N",
        "colab_type": "text"
      },
      "source": [
        "We'll need the following libraries:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq0Jgl-WNr9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the libraries we need for this lab\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfLxC9gFNr9V",
        "colab_type": "text"
      },
      "source": [
        "Set the random seed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbE4nO0LNr9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0b2b12f-8833-41e4-d9b2-75a58f93b53a"
      },
      "source": [
        "# Set the random seed\n",
        "\n",
        "torch.manual_seed(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f48a6b970d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szQURFb2Nr9Z",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "948i0VbjNr9a",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Log\">Logistic Function</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfDKmvGRNr9b",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor ranging from -100 to 100:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugS9A5waNr9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "aa6b9249-04f0-4bea-90da-3ff3c1ba54a4"
      },
      "source": [
        "z = torch.arange(-100, 100, 0.1).view(-1, 1)\n",
        "print(\"The tensor: \", z)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensor:  tensor([[-100.0000],\n",
            "        [ -99.9000],\n",
            "        [ -99.8000],\n",
            "        ...,\n",
            "        [  99.7000],\n",
            "        [  99.8000],\n",
            "        [  99.9000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbRdYMaSNr9g",
        "colab_type": "text"
      },
      "source": [
        "Create a sigmoid object: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk9ObSLfNr9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sigmoid object\n",
        "\n",
        "sig = nn.Sigmoid()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RiGtgF8Nr9k",
        "colab_type": "text"
      },
      "source": [
        "Apply the element-wise function Sigmoid with the object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekPbMF_6Nr9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use sigmoid object to calculate the \n",
        "\n",
        "yhat = sig(z)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7otB3VxNr9q",
        "colab_type": "text"
      },
      "source": [
        "Plot the results: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wG9LI5bNr9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1d73e724-dee1-470c-d0fc-233bf700243c"
      },
      "source": [
        "plt.plot(z.numpy(), yhat.numpy())\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('yhat')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'yhat')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EctBNJRNr9u",
        "colab_type": "text"
      },
      "source": [
        "Apply the element-wise Sigmoid from the function module and plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4K3Z6bNr9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "99f4a4d6-f035-41a6-815d-0a6d9b445eb8"
      },
      "source": [
        "yhat = torch.sigmoid(z)\n",
        "plt.plot(z.numpy(), yhat.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f485bf388d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWFklEQVR4nO3de4xc53nf8e/DJZc3kZRkLnUjaUqxLJh1a0vZqgaSuEZtN5LQirlXAoLErRGhQFQkcNpCgQrVUPuPbSRFk6hxGERwYsRWlLRJiZaBEjtK3BaVTMqWZV1Ci5Jli4wsri7lbbmX2X36x5xljkYzu0Pu7My+u98PsODMOYdzHp1596eH7zkzJzITSVL51gy6AElSbxjokrRCGOiStEIY6JK0QhjokrRCrB3Ujrdv35579uwZ1O4lqUhPPPHEa5k50m7dwAJ9z549HD58eFC7l6QiRcR3Oq1zykWSVggDXZJWCANdklYIA12SVggDXZJWiAUDPSIejIgTEfF0h/UREb8WEUcj4qmIuKn3ZUqSFtJNh/454JZ51t8KXF/93AX85uLLkiRdqAWvQ8/Mr0TEnnk22Qf8Xja/h/exiLg0Iq7KzFd6VKO07Ew2Znj2b07x3TfGOTXRYHyywVRjlgQyIcnqz2qBVPPh91zB+3Zd2vPX7cUHi64BXq49P1Yte1ugR8RdNLt4du/e3YNdS/01PtXgP/35t3joqy9zerLR9d+LWMKiVJwdWzcs20DvWmbuB/YDjI6O2raoKBPTM3zswUMc+s4b7Hvf1dzy3it5145L2LpxHZuH1zK8dg0BRET1Z/Ox1C+9CPTjwK7a853VMmlF+fW/eJ6vvvQG//mO97Pv/dcMuhzpbXpx2eIB4Geqq10+AJx0/lwrzcnxaR783y+x7/1XG+Zathbs0CPii8CHgO0RcQz498A6gMz8LHAQuA04CowD/3ypipUG5U+ePM656Rnu+uB1gy5F6qibq1zuXGB9Aj/fs4qkZehLz73KdSOb+TtXbxt0KVJHflJUWsDE9AyPv/gG/+iGHYMuRZqXgS4t4NlXTjE1M8vonssHXYo0LwNdWsA3j50E4H27nG7R8magSwt4+vhJtl8yzJVbNwy6FGleBrq0gG+/dpbvG7nEDwlp2TPQpQW89Po4e96xedBlSAsy0KV5nJ6Y5rUzk+zZbqBr+TPQpXl85/VxAPa8Y9OAK5EWZqBL83jl5AQAV1+6ccCVSAsz0KV5jJ2eBGDH1vUDrkRamIEuzePE6WaHvv0SA13Ln4EuzePE6Uku3zzMuiF/VbT8OUqleZw4NcmOLXbnKoOBLs1j7MwkIwa6CmGgS/MYOzVhoKsYBrrUQWYydmaSHVv8DheVwUCXOjg7NcP0THL55nWDLkXqioEudXDy3DQAWzcY6CqDgS51cHK8GejbNhroKoOBLnUw16Eb6CqFgS51cGqimnIx0FUIA13qwA5dpTHQpQ5OnbNDV1kMdKmDk+emiYAt69cOuhSpKwa61MGpc9Ns3bCONWu8l6jKYKBLHZw8N+38uYpioEsdnDw3zdaNTreoHAa61MGpiYafElVRDHSpg7OTDS7xhKgKYqBLHYxPzbDZQFdBDHSpg/GpBpuGhwZdhtS1rgI9Im6JiCMRcTQi7mmzfndEPBoRX4+IpyLitt6XKvXX2Uk7dJVlwUCPiCHgAeBWYC9wZ0Tsbdns3wEPZ+aNwB3Af+l1oVI/zcwm56Zn7NBVlG469JuBo5n5YmZOAQ8B+1q2SWBr9Xgb8De9K1Hqv3PTMwBsHrZDVzm6CfRrgJdrz49Vy+o+Cfx0RBwDDgL/qt0LRcRdEXE4Ig6PjY1dRLlSf4xPNgDYtN4OXeXo1UnRO4HPZeZO4Dbg8xHxttfOzP2ZOZqZoyMjIz3atdR7Z6fs0FWebgL9OLCr9nxntazu48DDAJn5f4ENwPZeFCgNwtm5Dt05dBWkm0A/BFwfEddGxDDNk54HWrb5LvBhgIh4D81Ad05FxRqf69C9ykUFWTDQM7MB3A08AjxH82qWZyLi/oi4vdrsl4Cfi4hvAF8EPpaZuVRFS0vt7JQdusrTVfuRmQdpnuysL7uv9vhZ4Ad6W5o0OOOTdugqj58UldqwQ1eJDHSpjbnLFr3KRSUx0KU25i5b9Dp0lcRAl9oYn2owtCYYHvJXROVwtEptnJuaZeO6ISK8n6jKYaBLbUw2Zli/1l8PlcURK7Ux2Zhlwzrnz1UWA11qY2LaDl3lccRKbUw2Zhk20FUYR6zUxsT0jFMuKo6BLrUx2Zh1ykXFccRKbUzaoatABrrUhh26SuSIldpwDl0lMtClNuzQVSJHrNSGHbpKZKBLbdihq0SOWKlFZtqhq0gGutSiMZvMJnboKo4jVmoxMd28uYUdukpjoEstJhuzAKxf56+HyuKIlVqc79DX2qGrLAa61MIOXaVyxEot5jr09XboKoyBLrWwQ1epHLFSC+fQVSoDXWphh65SOWKlFpN26CqUgS61sENXqRyxUgs/KapSdRXoEXFLRByJiKMRcU+HbX4qIp6NiGci4gu9LVPqn/Mdut/losKsXWiDiBgCHgA+ChwDDkXEgcx8trbN9cAvAz+QmW9GxI6lKlhaanboKlU3LcjNwNHMfDEzp4CHgH0t2/wc8EBmvgmQmSd6W6bUP5PTdugqUzcj9hrg5drzY9WyuncD746I/xMRj0XELe1eKCLuiojDEXF4bGzs4iqWlthkY5ahNcG6IQNdZenViF0LXA98CLgT+O2IuLR1o8zcn5mjmTk6MjLSo11LvTUxPWN3riJ1M2qPA7tqz3dWy+qOAQcyczozvw18i2bAS8Xx9nMqVTej9hBwfURcGxHDwB3AgZZt/oRmd05EbKc5BfNiD+uU+sbbz6lUCwZ6ZjaAu4FHgOeAhzPzmYi4PyJurzZ7BHg9Ip4FHgX+TWa+vlRFS0vJDl2lWvCyRYDMPAgcbFl2X+1xAp+ofqSi2aGrVLYhUgs7dJXKUSu1mJieYb0dugpkoEst7NBVKket1MI5dJXKQJdaTNmhq1COWqmFHbpKZaBLLZxDV6kctVILO3SVykCXWtihq1SOWqmmMTNLYzbt0FUkA12q8fZzKpmjVqrx9nMqmYEu1dihq2SOWqnGDl0lM9ClGjt0lcxRK9XYoatkBrpUY4eukjlqpZq5Dt3vQ1eJDHSpxg5dJXPUSjVzge4cukpkoEs156dc7NBVIEetVGOHrpIZ6FLN5PmTov5qqDyOWqnGk6IqmaNWqpmYniEChof81VB5HLVSzdzNLSJi0KVIF8xAl2q8/ZxKZqBLNZPT3n5O5XLkSjUTDTt0lctAl2rs0FUyR65UY4euknUV6BFxS0QciYijEXHPPNv9eERkRIz2rkSpf+zQVbIFR25EDAEPALcCe4E7I2Jvm+22AL8APN7rIqV+sUNXybppRW4Gjmbmi5k5BTwE7Guz3X8APgVM9LA+qa/s0FWybkbuNcDLtefHqmXnRcRNwK7M/J/zvVBE3BURhyPi8NjY2AUXKy21icaMN7dQsRbdikTEGuBXgV9aaNvM3J+Zo5k5OjIysthdSz03OT3LhrUGusrUTaAfB3bVnu+sls3ZArwX+MuIeAn4AHDAE6MqUfOTok65qEzdjNxDwPURcW1EDAN3AAfmVmbmyczcnpl7MnMP8Bhwe2YeXpKKpSXkR/9VsgUDPTMbwN3AI8BzwMOZ+UxE3B8Rty91gVI/TTRm7dBVrLXdbJSZB4GDLcvu67DthxZfltR/0zOzzMymc+gqlq2IVJm7n6hTLiqVgS5VJqbn7ifqr4XK5MiVKnMd+nqnXFQoA12qTDa8QbTK5siVKn875WKHrjIZ6FLFk6IqnYEuVc536H45lwrlyJUqdugqnYEuVSYaBrrKZqBLFa9DV+kcuVJl0g5dhTPQpcrfnhQ10FUmA12qnP+kqFMuKpQjV6pMTs8QgfcUVbEcuVJlotG8QXREDLoU6aIY6FLFuxWpdAa6VJmYnvGEqIpmoEuViWlvP6eyOXqlilMuKp2BLlXmTopKpXL0SpVzUw02Dtuhq1wGulQZn5ph8/DaQZchXTQDXaqcm5qxQ1fRDHSpcnaqYYeuohnoUmXcDl2FM9AlIDM5NzXDJgNdBTPQJWBqZpbGbLJ5vVMuKpeBLtE8IQqw0Q8WqWAGukRz/hxg83oDXeUy0CVgfKoBwEavclHBugr0iLglIo5ExNGIuKfN+k9ExLMR8VREfDki3tn7UqWlM9ehb3LKRQVbMNAjYgh4ALgV2AvcGRF7Wzb7OjCamX8P+CPg070uVFpK5wPdKRcVrJsO/WbgaGa+mJlTwEPAvvoGmfloZo5XTx8Ddva2TGlpzU25bHLKRQXrJtCvAV6uPT9WLevk48CftlsREXdFxOGIODw2NtZ9ldISO39S1OvQVbCenhSNiJ8GRoHPtFufmfszczQzR0dGRnq5a2lRxieryxYNdBWsm39fHgd21Z7vrJa9RUR8BLgX+IeZOdmb8qT+cMpFK0E3Hfoh4PqIuDYihoE7gAP1DSLiRuC3gNsz80Tvy5SW1vh0dVLUDl0FWzDQM7MB3A08AjwHPJyZz0TE/RFxe7XZZ4BLgD+MiCcj4kCHl5OWpTMTDdauCe9YpKJ19e/LzDwIHGxZdl/t8Ud6XJfUV6cnGmzZsJaIGHQp0kWzHZGA0xPTbNmwbtBlSItioEvAqapDl0pmoEvMdegGuspmoEvMzaE75aKyGegSzUDfaqCrcAa6BJxyykUrgIGuVW92Njkz2WCrga7CGeha9c5ONcjEOXQVz0DXqnfy3DQAWzfaoatsBrpWvTfPNgP98s3rB1yJtDgGula9N8anALh8s1MuKpuBrlXvjbPNb3u+bNPwgCuRFsdA16r3xvkpFwNdZTPQteq9eXaKoTXhB4tUPANdq97rZ6e4bNM61qzxq3NVNgNdq96bZ6e41PlzrQAGula9E6cn2LHFSxZVPgNdq973Tk5w5bYNgy5DWjQDXavazGzy6ulJrjLQtQIY6FrVXjszycxscuW2jYMuRVo0A12r2isnJwC42g5dK4CBrlXt+JvnAJxD14pgoGtV+/ZrZwC4dvvmAVciLZ6BrlXthbGzXL1tA5uG/epclc9A16r2wtgZrhu5ZNBlSD1hoGvVaszMcvTEGd61w0DXymCga9U68uppxqdmuHH3pYMuReoJA12r1te++/8AuGn3ZQOuROoNA12r1l8dOcHV2zaw8zI/VKSVwUDXqnRqYpqvPP8aP/zeK4nwa3O1MhjoWpW+8Ph3mWrM8mM37hx0KVLPdBXoEXFLRByJiKMRcU+b9esj4g+q9Y9HxJ5eFyr1ytETZ/j1Lz/Ph24Y4e/u3DbocqSeWfDTFBExBDwAfBQ4BhyKiAOZ+Wxts48Db2bmuyLiDuBTwD9bioKlizE9M8uxN8/x5ede5TcePcqGdUP8xx9576DLknqqm4/H3QwczcwXASLiIWAfUA/0fcAnq8d/BPxGRERmZg9rBeDhQy+z/3+9+JZl7XbTdsdtFrbbrtvXa/dfl+333H7bLo9Or+tpv113r9duy+5fbxH/Hd2+xx1WjE/PMDPbXPH391zGp3/ifey8bFOnV5CK1E2gXwO8XHt+DPgHnbbJzEZEnATeAbxW3ygi7gLuAti9e/dFFXzZ5mFuuGLL21e0Oa/V7lRXuxNg7bfr7et1WhFtFna/70W8XtsiB1RL29fr/kRlN/veNDzErss38v3vvIx37WgzfqQVoK9fYJGZ+4H9AKOjoxfVvX907xV8dO8VPa1LklaCbk6KHgd21Z7vrJa13SYi1gLbgNd7UaAkqTvdBPoh4PqIuDYihoE7gAMt2xwAfrZ6/BPAXyzF/LkkqbMFp1yqOfG7gUeAIeDBzHwmIu4HDmfmAeB3gM9HxFHgDZqhL0nqo67m0DPzIHCwZdl9tccTwE/2tjRJ0oXwk6KStEIY6JK0QhjokrRCGOiStELEoK4ujIgx4DsX+de30/Ip1GXCui7Mcq0Llm9t1nVhVmJd78zMkXYrBhboixERhzNzdNB1tLKuC7Nc64LlW5t1XZjVVpdTLpK0QhjokrRClBro+wddQAfWdWGWa12wfGuzrguzquoqcg5dkvR2pXbokqQWBrokrRDLPtAj4icj4pmImI2I0ZZ1v1zdmPpIRPxwbfm8N7Veghr/ICKerH5eiognq+V7IuJcbd1nl7qWlro+GRHHa/u/rbau7bHrU12fiYi/joinIuKPI+LSavlAj1dVQ1/Hzjx17IqIRyPi2Wr8/0K1vON72sfaXoqIb1b7P1wtuzwi/jwinq/+vKzPNd1QOyZPRsSpiPjFQRyviHgwIk5ExNO1ZW2PTzT9WjXenoqImxa188xc1j/Ae4AbgL8ERmvL9wLfANYD1wIv0Px636Hq8XXAcLXN3j7W+yvAfdXjPcDTAzx2nwT+dZvlbY9dH+v6x8Da6vGngE8tk+M10LHTUstVwE3V4y3At6r3re172ufaXgK2tyz7NHBP9fieufd0gO/j94B3DuJ4AR8EbqqP5U7HB7gN+FOad2L8APD4Yva97Dv0zHwuM4+0WbUPeCgzJzPz28BRmje0Pn9T68ycAuZuar3konkjzJ8CvtiP/S1Cp2PXF5n5Z5nZqJ4+RvMuWMvBwMZOq8x8JTO/Vj0+DTxH8969y9U+4Herx78L/MgAa/kw8EJmXuwn0RclM79C874QdZ2Ozz7g97LpMeDSiLjqYve97AN9Hu1uXn3NPMv74YeAVzPz+dqyayPi6xHxVxHxQ32qo+7u6p9yD9b+GTzIY9TqX9DsUOYM8ngtp+NyXkTsAW4EHq8WtXtP+ymBP4uIJ6J543eAKzLzlerx94BB3vj3Dt7aVA36eEHn49PTMbcsAj0ivhQRT7f5GUh31E6XNd7JWwfSK8DuzLwR+ATwhYjY2se6fhP4PuD9VS2/0st9L6KuuW3uBRrA71eLlvx4lSYiLgH+K/CLmXmKAb6nNT+YmTcBtwI/HxEfrK/M5lzCQK6HjuZtMm8H/rBatByO11ss5fHp6o5FSy0zP3IRf22+m1cvdFPrC7ZQjdG8OfaPAd9f+zuTwGT1+ImIeAF4N3B4sfV0W1etvt8G/kf1tJsbfy9pXRHxMeCfAB+uBnhfjtcClvy4XIiIWEczzH8/M/8bQGa+Wltff0/7JjOPV3+eiIg/pjlV9WpEXJWZr1RTBif6XVflVuBrc8dpORyvSqfj09Mxtyw69It0ALgjItZHxLXA9cBX6e6m1kvhI8BfZ+axuQURMRIRQ9Xj66oaX+xDLXP7r8/F/Sgwd9a907HrV123AP8WuD0zx2vLB3q8GNzYeZvqfMzvAM9l5q/Wlnd6T/tV1+aI2DL3mOYJ7qd5643ifxb47/2sq+Yt/0oe9PGq6XR8DgA/U13t8gHgZG1q5sL18+zvRZ4x/lGa80qTwKvAI7V199K8KuEIcGtt+W00rwp4Abi3T3V+DviXLct+HHgGeBL4GvBP+3zsPg98E3iqGjhXLXTs+lTXUZrzhk9WP59dDsdrUGOnQx0/SPOf5U/VjtNt872nfarrOppX/3yjeq/urZa/A/gy8DzwJeDyARyzzcDrwLbasr4fL5r/Q3kFmK6y6+Odjg/Nq1seqMbbN6ldyXcxP370X5JWiJKnXCRJNQa6JK0QBrokrRAGuiStEAa6JK0QBrokrRAGuiStEP8fJSYK/EpvgQwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwHFyJdMNr9x",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaYWImHqNr9y",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Seq\">Build a Logistic Regression with <code>nn.Sequential</code></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNHYl25FNr9z",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x1 tensor where x represents one data sample with one dimension, and 2x1 tensor X represents two data samples of one dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MijTIqm0Nr90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "66415968-4652-4bbd-d8d4-6eef44518653"
      },
      "source": [
        "# Create x and X tensor\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "X = torch.tensor([[1.0], [100]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1.]])\n",
            "X =  tensor([[  1.],\n",
            "        [100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK32MJwyNr94",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression object with the <code>nn.Sequential</code> model with a one-dimensional input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXqwKdQNr95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use sequential function to create model\n",
        "\n",
        "model = nn.Sequential(nn.Linear(1, 1), nn.Sigmoid())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfxh4QBNr9-",
        "colab_type": "text"
      },
      "source": [
        "The object is represented in the following diagram: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfOpIX8lNr9_",
        "colab_type": "text"
      },
      "source": [
        "<img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_regression_block_diagram.png\" width = 800, align = \"center\" alt=\"logistic regression block diagram\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyPAOo-oNr-A",
        "colab_type": "text"
      },
      "source": [
        "In this case, the parameters are randomly initialized. You can view them the following ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUMyN6tUNr-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a458fc5d-ac32-4810-e908-ce2f198e82f0"
      },
      "source": [
        "# Print the parameters\n",
        "\n",
        "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
        "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list(model.parameters()):\n",
            "  [Parameter containing:\n",
            "tensor([[0.2294]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.2380], requires_grad=True)]\n",
            "\n",
            "model.state_dict():\n",
            "  OrderedDict([('0.weight', tensor([[0.2294]])), ('0.bias', tensor([-0.2380]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RM_9PciNr-F",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0xmzPdSNr-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "619cb24d-d757-4759-eca8-ee33a29f9413"
      },
      "source": [
        "# The prediction for x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.4979]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auqZPqFeNr-J",
        "colab_type": "text"
      },
      "source": [
        "Calling the object with tensor <code>X</code> performed the following operation <b>(code values may not be the same as the diagrams value  depending on the version of PyTorch) </b>:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuhUXERmNr-K",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_functio_example%20.png\" width=\"400\" alt=\"Logistic Example\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ys-ji9ANr-L",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD6guNB9Nr-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57332ed3-0cd2-4699-8b54-3f82e85c2985"
      },
      "source": [
        "# The prediction for X\n",
        "\n",
        "yhat = model(X)\n",
        "yhat"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4979],\n",
              "        [1.0000]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPeaMSDTNr-P",
        "colab_type": "text"
      },
      "source": [
        "Calling the object performed the following operation: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrRWcmfnNr-P",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x2 tensor where x represents one data sample with one dimension, and 2x3 tensor X represents one data sample of two dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VLHHFLRNr-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "616766f3-959e-40e0-d1a8-8797893f2fc3"
      },
      "source": [
        "# Create and print samples\n",
        "\n",
        "x = torch.tensor([[1.0, 1.0]])\n",
        "X = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1., 1.]])\n",
            "X =  tensor([[1., 1.],\n",
            "        [1., 2.],\n",
            "        [1., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ONyCkmNNr-U",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression object with the <code>nn.Sequential</code> model with a two-dimensional input: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3GJv6xVNr-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create new model using nn.sequential()\n",
        "\n",
        "model = nn.Sequential(nn.Linear(2, 1), nn.Sigmoid())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-4SOEbNNr-Y",
        "colab_type": "text"
      },
      "source": [
        "The object will apply the Sigmoid function to the output of the linear function as shown in the following diagram:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6mO02ypNr-Z",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1logistic_output.png\" width=\"800\" alt=\"The structure of nn.sequential\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L844nCINr-Z",
        "colab_type": "text"
      },
      "source": [
        "In this case, the parameters are randomly initialized. You can view them the following ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1KMAeaSNr-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1f7ee83a-4444-4bbc-cafb-61ccf7ba8775"
      },
      "source": [
        "# Print the parameters\n",
        "\n",
        "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
        "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list(model.parameters()):\n",
            "  [Parameter containing:\n",
            "tensor([[ 0.1939, -0.0361]], requires_grad=True), Parameter containing:\n",
            "tensor([0.3021], requires_grad=True)]\n",
            "\n",
            "model.state_dict():\n",
            "  OrderedDict([('0.weight', tensor([[ 0.1939, -0.0361]])), ('0.bias', tensor([0.3021]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht01OhR3Nr-c",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "688SrlD9Nr-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5e6c0be-f7cb-4330-ff5e-c64b97b34f54"
      },
      "source": [
        "# Make the prediction of x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.6130]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjJ_wiZ4Nr-f",
        "colab_type": "text"
      },
      "source": [
        "The operation is represented in the following diagram:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocQ0MXJLNr-f",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.1.logisticwithouptut.png\" width=\"500\" alt=\"Sequential Example\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W05XzYi2Nr-g",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NzWDDd-Nr-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9e914be4-bf84-44e8-dde7-dd8019879673"
      },
      "source": [
        "# The prediction of X\n",
        "\n",
        "yhat = model(X)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.6130],\n",
            "        [0.6044],\n",
            "        [0.5957]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhhPGv3-Nr-k",
        "colab_type": "text"
      },
      "source": [
        "The operation is represented in the following diagram: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJGqkw7SNr-l",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.1.1_logistic_with_outputs2.png\" width=\"800\" alt=\"Sequential Example\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoNZyDsYNr-m",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUu1J3BkNr-n",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Model\">Build Custom Modules</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jACzvsH6Nr-o",
        "colab_type": "text"
      },
      "source": [
        "In this section, you will build a custom Module or class. The model or object function is identical to using <code>nn.Sequential</code>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9rjFiJpNr-p",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression custom module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl0w258oNr-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic_regression custom class\n",
        "\n",
        "class logistic_regression(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, n_inputs):\n",
        "        super(logistic_regression, self).__init__()\n",
        "        self.linear = nn.Linear(n_inputs, 1)\n",
        "    \n",
        "    # Prediction\n",
        "    def forward(self, x):\n",
        "        yhat = torch.sigmoid(self.linear(x))\n",
        "        return yhat"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyOAlK-nNr-u",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x1 tensor where x represents one data sample with one dimension, and 3x1 tensor where $X$ represents one data sample of one dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJGq2K04Nr-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b2ef61e1-3c73-4bd3-9da3-9c54cfbd6e68"
      },
      "source": [
        "# Create x and X tensor\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "X = torch.tensor([[-100], [0], [100.0]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1.]])\n",
            "X =  tensor([[-100.],\n",
            "        [   0.],\n",
            "        [ 100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe48s3JLNr-x",
        "colab_type": "text"
      },
      "source": [
        "Create a model to predict one dimension: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9syOCdXNr-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic regression model\n",
        "\n",
        "model = logistic_regression(1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToMwopw5Nr-0",
        "colab_type": "text"
      },
      "source": [
        "In this case, the parameters are randomly initialized. You can view them the following ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKlFN4zNNr-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8566eb8f-65a1-484b-92a6-6f8e9d74846d"
      },
      "source": [
        "# Print parameters \n",
        "\n",
        "print(\"list(model.parameters()):\\n \", list(model.parameters()))\n",
        "print(\"\\nmodel.state_dict():\\n \", model.state_dict())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list(model.parameters()):\n",
            "  [Parameter containing:\n",
            "tensor([[0.2381]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1149], requires_grad=True)]\n",
            "\n",
            "model.state_dict():\n",
            "  OrderedDict([('linear.weight', tensor([[0.2381]])), ('linear.bias', tensor([-0.1149]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6bJJJM7Nr-4",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILrQMFJeNr-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aba8c621-57ef-43c0-cbd7-ca728a4230e8"
      },
      "source": [
        "# Make the prediction of x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[0.5307]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E_ouneYNr-9",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93x7H5KINr-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "996a4c20-4593-4392-81ba-e0186fae0682"
      },
      "source": [
        "# Make the prediction of X\n",
        "\n",
        "yhat = model(X)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[4.0805e-11],\n",
            "        [4.7130e-01],\n",
            "        [1.0000e+00]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjAkFLrGNr_A",
        "colab_type": "text"
      },
      "source": [
        "Create a logistic regression object with a function with two inputs: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BJOM1IlNr_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic regression model\n",
        "\n",
        "model = logistic_regression(2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5JKK6DkNr_E",
        "colab_type": "text"
      },
      "source": [
        "Create a 1x2 tensor where x represents one data sample with one dimension, and 3x2 tensor X represents one data sample of one dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpPjAN43Nr_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6312b46e-be4d-4ca4-8d8c-6f7609637443"
      },
      "source": [
        "# Create x and X tensor\n",
        "\n",
        "x = torch.tensor([[1.0, 2.0]])\n",
        "X = torch.tensor([[100, -100], [0.0, 0.0], [-100, 100]])\n",
        "print('x = ', x)\n",
        "print('X = ', X)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  tensor([[1., 2.]])\n",
            "X =  tensor([[ 100., -100.],\n",
            "        [   0.,    0.],\n",
            "        [-100.,  100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdOa74z5Nr_J",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with one sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16lGLNBMNr_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7fc12441-46ed-46c4-c1c4-776227c0a1d3"
      },
      "source": [
        "# Make the prediction of x\n",
        "\n",
        "yhat = model(x)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[0.2943]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixCKJVFRNr_M",
        "colab_type": "text"
      },
      "source": [
        "Make a prediction with multiple samples: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2MQl08DNr_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d74a3041-687b-4320-8b8d-d1445948def1"
      },
      "source": [
        "# Make the prediction of X\n",
        "\n",
        "yhat = model(X)\n",
        "print(\"The prediction result: \\n\", yhat)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction result: \n",
            " tensor([[7.7529e-33],\n",
            "        [3.4841e-01],\n",
            "        [1.0000e+00]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVmyDgn-Nr_P",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffFxPWeUNr_Q",
        "colab_type": "text"
      },
      "source": [
        "<h3>Practice</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d8d1PsrNr_Q",
        "colab_type": "text"
      },
      "source": [
        "Make your own model <code>my_model</code> as applying linear regression first and then logistic regression using <code>nn.Sequential()</code>. Print out your prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4riBYF2LNr_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Practice: Make your model and make the prediction\n",
        "\n",
        "X = torch.tensor([-10.0])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzPz-GgzNr_T",
        "colab_type": "text"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- \n",
        "my_model = nn.Sequential(nn.Linear(1, 1),nn.Sigmoid())\n",
        "yhat = my_model(X)\n",
        "print(\"The prediction: \", yhat)\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbTyWb7jNr_T",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    }
  ]
}